{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7128d02",
   "metadata": {},
   "source": [
    "# HR Analytics Project- Understanding the Attrition in HR\n",
    "Problem Statement:\n",
    "Every year a lot of companies hire a number of employees. The companies invest time and money in training those employees, not just this but there are training programs within the companies for their existing employees as well. The aim of these programs is to increase the effectiveness of their employees. But where HR Analytics fit in this? and is it just about improving the performance of employees?\n",
    "\n",
    "HR Analytics\n",
    "\n",
    "Human resource analytics (HR analytics) is an area in the field of analytics that refers to applying analytic processes to the human resource department of an organization in the hope of improving employee performance and therefore getting a better return on investment. HR analytics does not just deal with gathering data on employee efficiency. Instead, it aims to provide insight into each process by gathering data and then using it to make relevant decisions about how to improve these processes.\n",
    "\n",
    "Attrition in HR\n",
    "\n",
    "Attrition in human resources refers to the gradual loss of employees overtime. In general, relatively high attrition is problematic for companies. HR professionals often assume a leadership role in designing company compensation programs, work culture, and motivation systems that help the organization retain top employees.\n",
    "\n",
    "How does Attrition affect companies? and how does HR Analytics help in analyzing attrition? We will discuss the first question here and for the second question, we will write the code and try to understand the process step by step.\n",
    "\n",
    "Attrition affecting Companies\n",
    "\n",
    "A major problem in high employee attrition is its cost to an organization. Job postings, hiring processes, paperwork, and new hire training are some of the common expenses of losing employees and replacing them. Additionally, regular employee turnover prohibits your organization from increasing its collective knowledge base and experience over time. This is especially concerning if your business is customer-facing, as customers often prefer to interact with familiar people. Errors and issues are more likely if you constantly have new workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4169ab2",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a999f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score , accuracy_score , recall_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229b8d9",
   "metadata": {},
   "source": [
    "# loading dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6cb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de245975",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc3cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb6a420",
   "metadata": {},
   "source": [
    "there are 1470 rows and 35 columns in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ea546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta data-Statistical information\n",
    "adf.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fc57e8a",
   "metadata": {},
   "source": [
    "Describing the dataset to obtain - Count , Mean , Standard deviation , Mininmum , IQR , Maximum values. \n",
    "From above we can observe there are Outliers in our dataset , So we need to remove these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the column names\n",
    "adf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1166f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta data-information abt the datatypes of columns\n",
    "adf.info()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d6c09f1",
   "metadata": {},
   "source": [
    "Out of 35 columns 26 columns are integer datatype and 9 columns are of object datatype. We can observe no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9eb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for any null vales\n",
    "adf.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b874538e",
   "metadata": {},
   "source": [
    "No missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46d9e6",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abaddc87",
   "metadata": {},
   "source": [
    "Plotting Countplot against the target variable.\n",
    "\n",
    "A count plot can be thought of as a histogram across a categorical , instead of quantitative, variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc3f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "sns.countplot('Age', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f581e025",
   "metadata": {},
   "source": [
    "The attrition is more in the age of 27 to around 45. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda019ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "sns.countplot('BusinessTravel', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4e00664",
   "metadata": {},
   "source": [
    "The employees who non-travel  have lowest attrition. and employees who travel rarely has highest attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "sns.countplot('Department', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da060102",
   "metadata": {},
   "source": [
    "Attrition is very less in Human resources department and it is high for Research and Development Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89328a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "sns.countplot('EducationField', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1787a52",
   "metadata": {},
   "source": [
    "Attrition is high in life sciences and less in Human resource and other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,9))\n",
    "sns.countplot('Gender', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "246fa88d",
   "metadata": {},
   "source": [
    "attrition is more in male candidates as compared to female candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,9))\n",
    "sns.countplot('JobRole', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edcb1cad",
   "metadata": {},
   "source": [
    "attrition is more for job role of sales executive, research scientist and laboratory Technician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb6978",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,9))\n",
    "sns.countplot('MaritalStatus', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d626f94",
   "metadata": {},
   "source": [
    "attrition is more in married employees as compared to single and divorced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,9))\n",
    "sns.countplot('OverTime', hue='Attrition', data=adf)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a2d9245",
   "metadata": {},
   "source": [
    "attrition is less in employees who dont do overtime"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02bbb671",
   "metadata": {},
   "source": [
    "Here our target variable is Attrition and other are our predictor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4029fbf",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19d62058",
   "metadata": {},
   "source": [
    "In our dataset there are two type of datatypes - Object and Integer .\n",
    "\n",
    "Finding columns with Object type ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_type = [feature for feature in adf.columns if adf[feature].dtypes =='O']\n",
    "print(object_type)\n",
    "print(\"Number of columns with object data type in adf is :\" , len(object_type))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f85a943a",
   "metadata": {},
   "source": [
    "Columns found above are of Object datatype.\n",
    "\n",
    "Finding datas with Integer datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abb9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_type = [feature for feature in adf.columns if adf[feature].dtypes !='O']\n",
    "print(integer_type)\n",
    "print(\"Number of columns with int64 data type is : \" , len(integer_type))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7b60816",
   "metadata": {},
   "source": [
    "From above we can observe that 9 columns are as object datatype and 25 columns are as integer datatype.\n",
    "\n",
    "Counting Values of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011804f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = ['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']\n",
    "for col in object_col:\n",
    "    print(col,'\\n',adf[col].value_counts() )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16bbb723",
   "metadata": {},
   "source": [
    "Here we can use LabelEncoder and it will also produce the same result , But here I have used .replace method to assign values explicitely."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc3fcb28",
   "metadata": {},
   "source": [
    "Attrition\n",
    "Attrition is our target variable , and has two categories so we'll transfrom its categories (Yes & No) to 1 & 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372a860",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.Attrition.replace({'Yes': 1, 'No': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e43d6ceb",
   "metadata": {},
   "source": [
    "Business Travel\n",
    "This column has three values\n",
    "1.Non-Travel\n",
    "2.Travel-Rarely\n",
    "3.Travel-Frequently\n",
    "\n",
    "so we will replace them by 0 , 1 , 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d69307",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.BusinessTravel.replace({'Non-Travel': 0, 'Travel_Rarely': 1, 'Travel_Frequently':2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fe07589",
   "metadata": {},
   "source": [
    "Department\n",
    "This column has three values\n",
    "1.Sales\n",
    "2.Research & Development\n",
    "3.Human Resources\n",
    "\n",
    "So we will convert them with 0 , 1 , 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.Department.replace({'Sales': 0, 'Research & Development': 1, 'Human Resources': 2, }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29cec9ef",
   "metadata": {},
   "source": [
    "EducationField\n",
    "\n",
    "This column has 6 values\n",
    "1.Life Sciences\n",
    "2.Medical\n",
    "3.Marketing\n",
    "4.Technical Degree\n",
    "5.Human Resources\n",
    "6.Other\n",
    "\n",
    "So we will convert these values with 0 , 1 , 2 , 3 , 4 , 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d48b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.EducationField.replace({'Life Sciences': 0, 'Medical': 1, 'Marketing': 2, \n",
    "                             'Technical Degree': 3, 'Human Resources': 4, 'Other':5},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['EducationField'].head(8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "668426cd",
   "metadata": {},
   "source": [
    "Gender\n",
    "\n",
    "This column has 2 values\n",
    "1.Male\n",
    "2.Female\n",
    "\n",
    "So we will convert them by 1 , 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.Gender.replace({'Male': 1, 'Female': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1c0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['Gender'].head(8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b0fb834",
   "metadata": {},
   "source": [
    "JobRole\n",
    "\n",
    "This column has nine values\n",
    "\n",
    "1.Sales Executive\n",
    "2.Research Scientist\n",
    "3.Laboratory Technician\n",
    "4.Manufacturing Director\n",
    "5.Healthcare Representative\n",
    "6.Manager\n",
    "7.Sales Representative\n",
    "8.Research Director\n",
    "9.Human Resources\n",
    "\n",
    "So we will convert them by 0 , 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.JobRole.replace({'Sales Executive': 0, 'Research Scientist': 1, 'Laboratory Technician': 2,\n",
    "                     'Manufacturing Director': 3, 'Healthcare Representative': 4, 'Manager': 5,\n",
    "                     'Sales Representative': 6, 'Research Director': 7, 'Human Resources': 8}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2f4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['JobRole']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f294ebc",
   "metadata": {},
   "source": [
    "MaritalStatus\n",
    "\n",
    "This column has 3 values\n",
    "\n",
    "1.Single\n",
    "2.Married\n",
    "3.Divorced\n",
    "\n",
    "So we will convert them by 0 , 1 , 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c2c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.MaritalStatus.replace({'Single': 0, 'Married': 1, 'Divorced': 2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c26d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['MaritalStatus']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "918bbf6b",
   "metadata": {},
   "source": [
    "Over18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845776de",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc6e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['Over18'].value_counts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6027814d",
   "metadata": {},
   "source": [
    "Here we can see that all employees are over 18 , so we can droop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.drop('Over18' , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19eec6c7",
   "metadata": {},
   "source": [
    "OverTime\n",
    "\n",
    "This colummn has two values\n",
    "\n",
    "1.Yes\n",
    "2.No\n",
    "\n",
    "So we will convert it by 1 , 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04486527",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf.OverTime.replace({'Yes': 1, 'No': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf['OverTime']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "917a0850",
   "metadata": {},
   "source": [
    "Checking for object values in the dataset if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8407bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_type = [feature for feature in adf.columns if adf[feature].dtypes =='O']\n",
    "print(object_type)\n",
    "print(\"Number of columns with object data type in adf is :\" , len(object_type))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a280876",
   "metadata": {},
   "source": [
    "We have sucessfully converted all our Object datatype columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9835ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4294ddb5",
   "metadata": {},
   "source": [
    "# Visualising Outliers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eaca6631",
   "metadata": {},
   "source": [
    "\n",
    "Boxplot\n",
    "\n",
    "A boxplot is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa3b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collist=adf.columns.values\n",
    "ncol=8\n",
    "nrows=5\n",
    "plt.figure(figsize=(16, 9 ))\n",
    "for i in range (0,len(collist)):\n",
    "    plt.subplot(nrows,ncol,i+1)\n",
    "    sns.boxplot(adf[collist[i]],color='darkcyan',orient='h')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b7ec3b8",
   "metadata": {},
   "source": [
    "\n",
    "We can observe that some of the columns has Outliers , so we need to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82658a65",
   "metadata": {},
   "source": [
    "# Removing Outliers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79fc66a3",
   "metadata": {},
   "source": [
    "\n",
    "Finding Zscore of our datas.\n",
    "\n",
    "A Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. If a Z-score is 0, it indicates that the data point's score is identical to the mean score. A Z-score of 1.0 would indicate a value that is one standard deviation from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334440dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score = np.abs(zscore(adf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eaa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(z_score>3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e8674be",
   "metadata": {},
   "source": [
    "\n",
    "From above arrays we can observe that first array shows row number and second array shows column number of values having Zscore > 3.\n",
    "\n",
    "adf_wo = Our DataFrame without Outliers ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_wo = adf.drop([  28,   45,   62,   62,   63,   64,   85,   98,   98,  110,  123,\n",
    "        123,  123,  126,  126,  126,  153,  178,  187,  187,  190,  190,\n",
    "        218,  231,  231,  237,  237,  270,  270,  281,  326,  386,  386,\n",
    "        401,  411,  425,  425,  427,  445,  466,  473,  477,  535,  561,\n",
    "        561,  584,  592,  595,  595,  595,  616,  624,  635,  653,  653,\n",
    "        677,  686,  701,  716,  746,  749,  752,  799,  838,  861,  861,\n",
    "        875,  875,  894,  914,  914,  918,  922,  926,  926,  937,  956,\n",
    "        962,  976,  976, 1008, 1024, 1043, 1078, 1078, 1086, 1086, 1093,\n",
    "       1111, 1116, 1116, 1135, 1138, 1138, 1156, 1184, 1221, 1223, 1242,\n",
    "       1295, 1301, 1301, 1303, 1327, 1331, 1348, 1351, 1401, 1414, 1430])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55baf93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_wo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72201973",
   "metadata": {},
   "source": [
    "Here above we have successfully removed all the rows having outliers."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b09e5f97",
   "metadata": {},
   "source": [
    "columnss = ['Attrition','Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeCount', 'EmployeeNumber', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3c7e3",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a437157d",
   "metadata": {},
   "source": [
    "Visualizing Correlation between our predictor variable and target variable ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f14743",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24,12))\n",
    "sns.heatmap(adf_wo.corr()  , cmap = 'YlGnBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = adf_wo.corr()\n",
    "corr_df  = corr_df.iloc[: , 1:2]\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b894048a",
   "metadata": {},
   "source": [
    "\n",
    "From above we can observe that some columns are internally correlated ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d13b40",
   "metadata": {},
   "source": [
    "# Skewness"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec418948",
   "metadata": {},
   "source": [
    "Checking for Skewness in our dataset[features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predictor = adf_wo.drop('Attrition', axis = 1)\n",
    "x_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89712757",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predictor.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd795537",
   "metadata": {},
   "source": [
    "# DistPlot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "949771a9",
   "metadata": {},
   "source": [
    "This function combines the matplotlib hist function (with automatic calculation of a good default bin size) with the seaborn kdeplot() and rugplot() functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef2998",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in x_predictor :\n",
    "    sns.distplot(x_predictor[feature] , kde = True , color = 'darkcyan' )\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1fe7cda",
   "metadata": {},
   "source": [
    "The rule of thumb seems to be: If the skewness is between -0.5 and 0.5, the data are fairly symmetrical. If the skewness is between -1 and – 0.5 or between 0.5 and 1, the data are moderately skewed. If the skewness is less than -1 or greater than 1, the data are highly skewed.\n",
    "\n",
    "Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "powert = PowerTransformer( method = 'yeo-johnson' , standardize = False)\n",
    "x_t = powert.fit_transform(x_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb84bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0921f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trans = pd.DataFrame(x_t , columns = x_predictor.columns)\n",
    "x_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e3350",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trans.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6349c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in x_trans :\n",
    "    sns.distplot(x_trans[feature] , kde = True , color = 'darkcyan' )\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "058e403c",
   "metadata": {},
   "source": [
    "Here we can see that we have successfully removed skewness of our dataset.\n",
    "\n",
    "Checking for min and max values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_trans :\n",
    "    print(i , max(x_trans[i]) - min(x_trans[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c452b09",
   "metadata": {},
   "source": [
    "We can see that there is vast different between values of different columns , So we will scale them .\n",
    "\n",
    "Gaussian's distribution with zero mean and unit variance is standard scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcab23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_s = scaler.fit_transform(x_trans)\n",
    "x_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b10b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sc = pd.DataFrame(x_s , columns = x_trans.columns)\n",
    "x_sc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c5a9e02",
   "metadata": {},
   "source": [
    "Here we can drop EmployeeNumber column as its not worth taking forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30638df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sc = x_sc.drop('EmployeeNumber' , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb24a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cda00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20,9))\n",
    "sns.heatmap(x_sc.corr() , cmap = 'Spectral')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7738990",
   "metadata": {},
   "source": [
    "From above heatmap we can observe that some predictor columns are highly correlated . So we will use PCA for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916682f7",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0a16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 'mle' , svd_solver = 'full' )\n",
    "xpca = pca.fit_transform(x_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7373077",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f = pd.DataFrame(xpca )\n",
    "x_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_f.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94c3035a",
   "metadata": {},
   "source": [
    "From above we can observe that the columns are reduced to 28 from 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f715be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = adf_wo.iloc[: ,1:2 ]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344600d",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding best Random State\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(0,200):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=i)\n",
    "    rf=RandomForestClassifier()\n",
    "    rf.fit(X_train,y_train)\n",
    "    predrf=rf.predict(X_test)\n",
    "    acc=accuracy_score(y_test,predrf)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "    \n",
    "print('Best accuracy is ',maxAccu, 'on random state ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3379a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "             KNeighborsClassifier(),\n",
    "             SVC(),\n",
    "             RandomForestClassifier(),\n",
    "             AdaBoostClassifier(),\n",
    "             DecisionTreeClassifier(),\n",
    "             GaussianNB()\n",
    "         ]\n",
    "\n",
    "names = ['LogisticRegression','K Nearest Neighbor','Support Vector Classifier','Random Forest','AdaBoost Classifier',\n",
    "         'Decision Tree Classifier' , 'GaussianNB' ]\n",
    "\n",
    "for model,name in zip(models,names):\n",
    "    fit = model.fit(X_train , y_train)\n",
    "    y_predicted = model.predict(X_test)\n",
    "    score = model.score(X_train , y_train)\n",
    "    print(name ,\" - \" ,score)\n",
    "    print(\"Accuracy:\",accuracy_score(y_predicted, y_test))\n",
    "    print(\"Confusion Matrix:\\n\",confusion_matrix(y_predicted, y_test))\n",
    "    print(\"\\t\\tclassification report\")\n",
    "    print(\"-\" * 52)\n",
    "    print(classification_report(y_predicted , y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d85d19b",
   "metadata": {},
   "source": [
    "From above we can conclude that Support Vector Classifier , AdaBoost Classifier , Random Forest Classifier and Decision Tree Classifier have the best scores so we will use these algorithms for our future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da92664",
   "metadata": {},
   "source": [
    "# Support Vector Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e040dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(0,200):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=i)\n",
    "    sv = SVC()\n",
    "    sv.fit(X_train,y_train)\n",
    "    predsv = sv.predict(X_test)\n",
    "    acc=accuracy_score(y_test,predsv)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "    \n",
    "print('Best accuracy is ',maxAccu, 'on random state ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e75b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=99)\n",
    "sv = SVC()\n",
    "sv.fit(X_train , y_train)\n",
    "sv_predicted = sv.predict(X_test)\n",
    "score = sv.score(X_train , y_train)\n",
    "\n",
    "print(SVC() ,\" - \" ,score)\n",
    "print(\"Accuracy:\",accuracy_score(sv_predicted, y_test))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(sv_predicted, y_test))\n",
    "print(\"\\t\\tclassification report\")\n",
    "print(\"-\" * 52)\n",
    "print(classification_report(sv_predicted , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacd529",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e1f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(0,200):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=i)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train,y_train)\n",
    "    predrf = rf.predict(X_test)\n",
    "    acc=accuracy_score(y_test,predrf)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "    \n",
    "print('Best accuracy is ',maxAccu, 'on random state ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3810fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=106)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train , y_train)\n",
    "rf_predicted = rf.predict(X_test)\n",
    "score = rf.score(X_train , y_train)\n",
    "\n",
    "print(RandomForestClassifier() ,\" - \" ,score)\n",
    "print(\"Accuracy:\",accuracy_score(rf_predicted, y_test))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(rf_predicted, y_test))\n",
    "print(\"\\t\\tclassification report\")\n",
    "print(\"-\" * 52)\n",
    "print(classification_report(rf_predicted , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61310554",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca2533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(0,200):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=i)\n",
    "    dtr = DecisionTreeClassifier()\n",
    "    dtr.fit(X_train,y_train)\n",
    "    preddtr = dtr.predict(X_test)\n",
    "    acc=accuracy_score(y_test,preddtr)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "    \n",
    "print('Best accuracy is ',maxAccu, 'on random state ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ca3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=106)\n",
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(X_train , y_train)\n",
    "dtr_predicted = dtr.predict(X_test)\n",
    "score = dtr.score(X_train , y_train)\n",
    "\n",
    "print(DecisionTreeClassifier() ,\" - \" ,score)\n",
    "print(\"Accuracy:\",accuracy_score(dtr_predicted, y_test))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(dtr_predicted, y_test))\n",
    "print(\"\\t\\tclassification report\")\n",
    "print(\"-\" * 52)\n",
    "print(classification_report(dtr_predicted , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bf6d63",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxAccu=0\n",
    "maxRS=0\n",
    "for i in range(0,200):\n",
    "    X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=i)\n",
    "    ab = AdaBoostClassifier()\n",
    "    ab.fit(X_train,y_train)\n",
    "    predab = ab.predict(X_test)\n",
    "    acc=accuracy_score(y_test,predab)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu=acc\n",
    "        maxRS=i\n",
    "    \n",
    "print('Best accuracy is ',maxAccu, 'on random state ',maxRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de70a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=166)\n",
    "ab = AdaBoostClassifier()\n",
    "ab.fit(X_train , y_train)\n",
    "ab_predicted = ab.predict(X_test)\n",
    "score = ab.score(X_train , y_train)\n",
    "\n",
    "print(AdaBoostClassifier() ,\" - \" ,score)\n",
    "print(\"Accuracy:\",accuracy_score(ab_predicted, y_test))\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(ab_predicted, y_test))\n",
    "print(\"\\t\\tclassification report\")\n",
    "print(\"-\" * 52)\n",
    "print(classification_report(ab_predicted , y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1810c",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf785dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate':[0.001, 0.10, 0.1, 1],\n",
    "\n",
    "             'n_estimators':range(50, 400, 50)\n",
    "             }\n",
    "\n",
    "\n",
    "ab = AdaBoostClassifier( random_state = 166)\n",
    "\n",
    "\n",
    "grid_ab = GridSearchCV(ab , param_grid, scoring = 'accuracy')\n",
    "grid_ab.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyper Parameters:\\n\",grid_ab.best_params_)\n",
    "print(\"training accuracy:\\n\",grid_ab.best_score_)\n",
    "ab_grid_pred = grid_ab.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(ab_grid_pred , y_test))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\",confusion_matrix(ab_grid_pred , y_test))\n",
    "print(\"\\t\\tclassification report\")\n",
    "print(\"-\" * 52)\n",
    "print(classification_report(ab_grid_pred , y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7326d361",
   "metadata": {},
   "source": [
    "From above we can observe that Random Forest Classifier is giving the best scores for our Predictions ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca4696",
   "metadata": {},
   "source": [
    "# Training Random Forest Classifier again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x_f,y,test_size=.30,random_state=106)\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, oob_score = True)\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_prediction = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "print(round(acc_random_forest,2,), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00e429",
   "metadata": {},
   "source": [
    "# Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05228eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \n",
    "              \"min_samples_leaf\" : [1, 5, 10, 25, 50, 70], \n",
    "              \"min_samples_split\" : [2, 4, 10, 12, 16, 18, 25, 35], \n",
    "              \"n_estimators\": [100, 400, 700, 1000, 1500]}\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f2bf655",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cross_val_predict(random_forest, X_train, y_train, cv=3)\n",
    "confusion_matrix(y_train, predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d909d1d",
   "metadata": {},
   "source": [
    "Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\", precision_score(y_train, predictions))\n",
    "print(\"Recall:\",recall_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "151f8825",
   "metadata": {},
   "source": [
    "Getting the Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = random_forest.predict_proba(X_train)\n",
    "y_scores = y_scores[:,1]\n",
    "\n",
    "precision, recall, threshold = precision_recall_curve(y_train, y_scores)\n",
    "def plot_precision_and_recall(precision, recall, threshold):\n",
    "    plt.plot(threshold, precision[:-1], \"r-\", label=\"precision\", linewidth=5)\n",
    "    plt.plot(threshold, recall[:-1], \"b\", label=\"recall\", linewidth=5)\n",
    "    plt.xlabel(\"threshold\", fontsize=19)\n",
    "    plt.legend(loc=\"upper right\", fontsize=19)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_precision_and_recall(precision, recall, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f42119d",
   "metadata": {},
   "source": [
    "# ROC_AUC Curve\n",
    "\n",
    "This curve plots the true positive rate (also called recall) against the false positive rate (ratio of incorrectly classified negative instances), instead of plotting the precision versus the recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1573e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, y_scores)\n",
    "\n",
    "# plotting them against each other\n",
    "\n",
    "def plot_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
    "    plt.plot(false_positive_rate, true_positive_rate, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'r', linewidth=4)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate (FPR)', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate (TPR)', fontsize=16)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plot_roc_curve(false_positive_rate, true_positive_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82255e46",
   "metadata": {},
   "source": [
    "# Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rf,'RandomForestClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf7709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf72306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56079cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b807cf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d130685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9baa95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221aa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bb4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
